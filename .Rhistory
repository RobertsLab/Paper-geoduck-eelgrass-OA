# Tidal height
Tide.Data <- Env.Data[,c(1,grep("Tide", colnames(Env.Data)))]
names(Tide.Data) <- c("DateTime", "FB", "PG", "CI", "WB")
Tide.Data.melted <- melt(Tide.Data, id="DateTime")
Tide.Data.melted.noNA <- Tide.Data.melted[which(!is.na(Tide.Data.melted$value)),]
Tide.series <- plot_ly(data = Tide.Data.melted.noNA, x = ~DateTime, y = ~value, type="scatter", mode="lines", color=~variable, hovertext=~value) %>%
layout(title="Tidal height across sites (raw data),\n2016 DNR outplant",
yaxis = list(title = 'Tidal Height'),
legend = list(x=.95, y=.95))
# Create master melted dataframe with all environmental data
# First, add another column "metric" to each env. data frame
pH.Data.melted.noNA$metric <- c("pH")
T.Data.melted.noNA$metric <- c("Temperature")
DO.Data.melted.noNA$metric <- c("DO")
S.Data.melted.noNA$metric <- c("Salinity")
Tide.Data.melted.noNA$metric <- c("Tide")
# Identify any time points in pH, DO & S that where probes were exposed. NOTE: likely need to update the threshold based on Micah/Alex's input.
Tide.sites <- as.factor(c("FB", "PG", "CI", "WB"))
Tide.exposed <- c(-1.25, 0, -1.0, 1.5) #tide depth at which probes are exposed (estimated)
submerged.times = list()
for (i in 1:length(Tide.sites)) {
submerged.times[[i]] <- Tide.Data.melted.noNA[which(Tide.Data.melted.noNA$value>=Tide.exposed[i] & Tide.Data.melted.noNA$variable %in% Tide.sites[[i]]), ]
}
# Filter pH, DO & S at time points where probes were exposed
Tide.location <- as.factor(c("FB-B", "FB-E", "PG-B", "PG-E", "CI-B", "CI-E", "WB-B", "WB-E"))
J <- c(1,1,2,2,3,3,4,4)
submerged.data = list()
for (i in 1:length(Tide.location)) {
submerged.data[[i]] <- rbind(pH.Data.melted.noNA[which(pH.Data.melted.noNA$DateTime %in% submerged.times[[J[i]]]$DateTime & pH.Data.melted.noNA$variable %in% Tide.location[[i]]), ], DO.Data.melted.noNA[which(DO.Data.melted.noNA$DateTime %in% submerged.times[[J[i]]]$DateTime & DO.Data.melted.noNA$variable %in% Tide.location[[i]]), ], S.Data.melted.noNA[which(S.Data.melted.noNA$DateTime %in% submerged.times[[J[i]]]$DateTime & S.Data.melted.noNA$variable %in% Tide.location[[i]]), ])
}
# Combine results from the previous for loop for pH, DO & Salinity, and the Temp and Tide data (unedited) into one master env. data frame (long form)
Env.Data.Master <- do.call(rbind, submerged.data)
Env.Data.Master <- rbind(Env.Data.Master, T.Data.melted.noNA, Tide.Data.melted.noNA) #this is a dataframe with env. data, screened for times when pH, DO & S probes were exposed
Env.Data.Master$metric <- as.factor(Env.Data.Master$metric)
# Remove DO data from FBE after 6/24 @ 08:40:00, as the probe clearly malfunctioned after that time.
Env.Data.Master <- subset(Env.Data.Master, !(variable=="FB-E" & metric=="DO" & DateTime > "2016-06-24 08:40:00"))
# Remove Salinity data where probes exposed / malfunctioned (zero time points, identified via plots)
Env.Data.Master <- subset(Env.Data.Master, !((variable=="CI-E" & metric=="Salinity") | (variable=="FB-B" & metric=="Salinity" & DateTime > "2016/07/03 09:50:00") | (variable=="WB-B" & metric=="Salinity" & DateTime > "2016/06/25 05:30:00")))
# Identify and remove outliers from pH, DO & Salinity data. Apply Tukey's method of removing outlying values, where values outside the inner fence removed:
Env.Data.Master.noOuts <- Env.Data.Master
# pH Data
for(i in 1:length(Tide.location)) { #For individual site data
IQR <- quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "pH" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[4] - quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "pH" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[2]
upperBound <- as.numeric(quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "pH" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[4] + 1.5*IQR) #calculate upper bound
lowerBound <- as.numeric(quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "pH" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[2] - 1.5*IQR) #calculate lower bound
Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$metric %in% "pH" & Env.Data.Master.noOuts$variable %in% Tide.location[i] & Env.Data.Master.noOuts$value > upperBound), "value"] <- NA #replace values higher than upper bound with NA
Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$metric %in% "pH" & Env.Data.Master.noOuts$variable %in% Tide.location[i] & Env.Data.Master.noOuts$value < lowerBound), "value"] <- NA #replace values lower than lower bound with NA
}
# DO Data
for(i in 1:length(Tide.location)) { #For individual site data
IQR <- quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "DO" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[4] - quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "DO" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[2]
upperBound <- as.numeric(quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "DO" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[4] + 1.5*IQR) #replace values higher than upper bound with NA
lowerBound <- 0 #DO cannot be less than 0
Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$metric %in% "DO" & Env.Data.Master.noOuts$variable %in% Tide.location[i] & Env.Data.Master.noOuts$value > upperBound), "value"] <- NA
Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$metric %in% "DO" & Env.Data.Master.noOuts$variable %in% Tide.location[i] & Env.Data.Master.noOuts$value < lowerBound), "value"] <- NA
}
# Salinity Data
for(i in 1:length(Tide.location)) { #For individual site data
IQR <- quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "Salinity" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[4] - quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "Salinity" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[2]
upperBound <- as.numeric(quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "Salinity" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[4] + 1.5*IQR) #calculate upper bound
lowerBound <- as.numeric(quantile(Env.Data.Master[which(Env.Data.Master$metric %in% "Salinity" & Env.Data.Master$variable %in% Tide.location[i]),"value"], na.rm=TRUE)[2] - 1.5*IQR) #calculate lower bound
Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$metric %in% "Salinity" & Env.Data.Master.noOuts$variable %in% Tide.location[i] & Env.Data.Master.noOuts$value > upperBound), "value"] <- NA #replace values higher than upper bound with NA
Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$metric %in% "Salinity" & Env.Data.Master.noOuts$variable %in% Tide.location[i] & Env.Data.Master.noOuts$value < lowerBound), "value"] <- NA #replace values lower than lower bound with NA
}
# Remove the NA entries
Env.Data.Master.noOuts <- Env.Data.Master.noOuts[which(!is.na(Env.Data.Master.noOuts$value)),]
# Remove SK entries
Env.Data.Master.noOuts <- subset(Env.Data.Master.noOuts, variable!="SK-E")
Env.Data.Master.noOuts <- subset(Env.Data.Master.noOuts, variable!="SK-B")
# Geoduck were outplanted from ~June 21 -> July 22, extract only environmental data from this time span
Env.Data.Master.noOuts.geo <- Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$DateTime >= "2016-06-21 00:00:00"),]
# Save this outlier-scrubbed dataset as .csv
write.csv(file="results/Environmental/EnvData-Melted-NoOutliers.csv",Env.Data.Master.noOuts, col.names = T, row.names=F)
# Geoduck were outplanted from ~June 21 -> July 22, extract only environmental data from this time span
Env.Data.Master.noOuts.geo <- Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$DateTime >= "2016-06-21 00:00:00"),]
Env.Data.Master.noOuts
# Save this outlier-scrubbed dataset as .csv
write.csv(file="results/Environmental/EnvData-Melted-NoOutliers.csv",Env.Data.Master.noOuts, row.names=F)
# Geoduck were outplanted from ~June 21 -> July 22, extract only environmental data from this time span
Env.Data.Master.noOuts.geo <- Env.Data.Master.noOuts[which(Env.Data.Master.noOuts$DateTime >= "2016-06-21 00:00:00"),]
# ==> pH
pH.series.noOuts <- plot_ly(data = subset(Env.Data.Master.noOuts.geo, metric=="pH"), x = ~DateTime, y = ~value, type="scatter", mode="lines", color=~variable, hovertext=~value) %>%  #generate plotly plot
layout(title="pH across sites (outliers removed)\n2016 DNR outplant",
yaxis = list(title = 'pH (total scale)'),
legend = list(x=.95, y=.95))
Salinity.series.noOuts <- plot_ly(data = subset(Env.Data.Master.noOuts.geo, metric=="Salinity"), x = ~DateTime, y = ~value, type="scatter", mode="lines", color=~variable, hovertext=~value) %>%  #generate plotly plot
layout(title="Salinity across sites (outliers removed)\n2016 DNR outplant",
yaxis = list(title = 'Salinity'),
legend = list(x=.95, y=.95))
DO.series.noOuts <- plot_ly(data = subset(Env.Data.Master.noOuts.geo, metric=="DO"), x = ~DateTime, y = ~value, type="scatter", mode="lines", color=~variable, hovertext=~value) %>%  #generate plotly plot
layout(title="DO across sites (outliers removed)\n2016 DNR outplant",
yaxis = list(title = 'Dissolved Oxygen (mg/L)'),
legend = list(x=.95, y=.95))
Temperature.series.noOuts <- plot_ly(data = subset(Env.Data.Master.noOuts.geo, metric=="Temperature"), x = ~DateTime, y = ~value, type="scatter", mode="lines", color=~variable, hovertext=~value) %>%  #generate plotly plot
layout(title="Temperature across sites (outliers removed)\n2016 DNR outplant",
yaxis = list(title = 'Temperature (C)'),
legend = list(x=.95, y=.95))
pH.series.noOuts
# Join outlier-scrubbed master environmental dataset with metadata
metadata <- aggregate(Region ~ Bay + Habitat +Sample.Shorthand, data.melted.plus.pepsum, FUN=unique)
Env.Data.Master.noOuts.geo <- merge(x=Env.Data.Master.noOuts.geo, y=metadata, by.x = "variable", by.y = "Sample.Shorthand", all.x=T, all.y=T)
# Pull summary statistics for each environmental variable by location
EnvSum <- set_colnames(aggregate(value ~ variable*metric + Bay + Habitat + Region, Env.Data.Master.noOuts.geo, mean), c("variable", "metric", "Bay", "Habitat", "Region", "Mean"))
Env.Data.Master.noOuts.geo
metadata
# Join outlier-scrubbed master environmental dataset with metadata
metadata <- aggregate(Region ~ Bay + Habitat +Sample.Shorthand, data.melted.plus.pepsum, FUN=unique)
# Import datasets using relative paths in this repo
SRMreport <- read.csv("data/SRM/2017-Geoduck-SRM-Skyline-Report.csv", header=FALSE, na.strings = "#N/A", stringsAsFactors = FALSE)
SRMsequence <- read.csv("data/SRM/SRM-Sequence-final-annotated.csv", header=TRUE, stringsAsFactors = FALSE)
# Re-load sample key
sample.key <- read.csv("data/Geoduck-sample-info.csv", header=TRUE, stringsAsFactors = FALSE)
SRMsamples <- sample.key[sample.key$MS.MS.Start.Date == "7/18/17", "PRVial"]
# Replace technical replicate / file names with sample names
rep.names <- SRMreport[1,] # create vector of replicate names
rep.names.short <- noquote(gsub(' Area', '', rep.names)) # remove Area from rep name, and don't include quotes
repsTOsamples <- as.data.frame(SRMsequence[,c(2,3,5)])
repsTOsamples.filtered <- filter(repsTOsamples, repsTOsamples[,1] %in% rep.names.short)
samples <- as.character(repsTOsamples.filtered$Sample...rep.name)
other.headers <- as.character(rep.names.short[1:4])
samples.vector <- noquote(c(other.headers, samples))
SRM.data <- SRMreport[-1,]
colnames(SRM.data) <- samples.vector
# Create separate reports for dilution curve data and sample data
SRM.dilution.data <- SRM.data[-1,c(grepl("Protein Name|Transition|Peptide Sequence|Fragment Ion|^D.-G$", colnames(SRM.data)))]  #dilution curve data
SRM.sample.data <- (SRM.data[,c(!grepl("^D.-G$", colnames(SRM.data)))]) #sample data
##Annotate sample names with Bay and Habitat
repsTOsamples.filtered.annotated <- merge(x=repsTOsamples.filtered, y=sample.key[,c("Bay", "Habitat", "Exclosure", "PRVial", "Sample.Shorthand")], by.x="Comment", by.y = "PRVial", all.x=T, all.y=F)
#as.data.frame(filter(sample.key[,c(3,5,6,8,9)], sample.key$PRVial %in% repsTOsamples.filtered$Comment)) #pull bay & habitat from sample key
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G053-remake"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("FB", "FB","E","E","FBE-2","FBE-2","FB-E","FB-E")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G071-A"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("PG","PG","E","E","PGE-2","PGE-2","PG-E","PG-E")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G071-B"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("PG","PG","E","E","PGE-2","PGE-2","PG-E","PG-E")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G104-remake"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("WB","WB","B","B","WBB-4","WBB-4","WB-B","WB-B")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G114-remake"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("WB","WB","B","B","WBB-6","WBB-6","WB-B","WB-B")
repsTOsamples.filtered.annotated <- repsTOsamples.filtered.annotated[-1:-8,] #remove dilution curve sample info
# Subset sample names for site & treatment combos
CI.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "CI-E"),]
CI.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "CI-B"),]
PG.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "PG-E"),]
PG.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "PG-B"),]
WB.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "WB-E"),]
WB.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "WB-B"),]
FB.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "FB-E"),]
FB.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "FB-B"),]
# Isolate just sample names for each site/treatment combo
CI.E.samples <- unique(CI.E$Comment)
CI.B.samples <- unique(CI.B$Comment)
PG.E.samples <- unique(PG.E$Comment)
PG.B.samples <- unique(PG.B$Comment)
WB.E.samples <- unique(WB.E$Comment)
WB.B.samples <- unique(WB.B$Comment)
FB.E.samples <- unique(FB.E$Comment)
FB.B.samples <- unique(FB.B$Comment)
# Isolate eelgrass and bare group sample names
Eelgrass.samples <- c(CI.E.samples, PG.E.samples, WB.E.samples, FB.E.samples)
Bare.samples <- c(CI.B.samples, PG.B.samples, WB.B.samples, FB.B.samples)
### Convert Area data to numeric format
SRM.data.numeric[,5:120] <- as.numeric(as.character(unlist(SRM.data.numeric[,5:120]))) # NOTE: this is a handy method of converting tricky data to numeric
## Name each row with a unique transition ID
nTransitions <- length(SRM.data.numeric$Transition) # How many transitions are there
Transition.ID <- vector(length=nTransitions) # create empty vector with length= number of transitions
for (i in 1:nTransitions) {
Transition.ID[i] <- paste(SRM.data.numeric[i,3], SRM.data.numeric[i,4])}  # loop that fills empty vector with unique transition ID, built from the peptide sequence (column 3) and the fragment ion (columm 4)
length(SRM.data.numeric$Transition) == length(Transition.ID) # confirm that I didn't lose any transitions; should equal TRUE
row.names(SRM.data.numeric) <- Transition.ID # assign newly created transition IDs as row names
write.csv(SRM.data.numeric, file="data/SRM/SRM-data-annotated.csv") #write this file out for safe keeping
# Isolate eelgrass and bare group sample names
Eelgrass.samples <- c(CI.E.samples, PG.E.samples, WB.E.samples, FB.E.samples)
# Import datasets using relative paths in this repo
SRMreport <- read.csv("data/SRM/2017-Geoduck-SRM-Skyline-Report.csv", header=FALSE, na.strings = "#N/A", stringsAsFactors = FALSE)
SRMsequence <- read.csv("data/SRM/SRM-Sequence-final-annotated.csv", header=TRUE, stringsAsFactors = FALSE)
# Re-load sample key
sample.key <- read.csv("data/Geoduck-sample-info.csv", header=TRUE, stringsAsFactors = FALSE)
SRMsamples <- sample.key[sample.key$MS.MS.Start.Date == "7/18/17", "PRVial"]
# Replace technical replicate / file names with sample names
rep.names <- SRMreport[1,] # create vector of replicate names
rep.names.short <- noquote(gsub(' Area', '', rep.names)) # remove Area from rep name, and don't include quotes
repsTOsamples <- as.data.frame(SRMsequence[,c(2,3,5)])
repsTOsamples.filtered <- filter(repsTOsamples, repsTOsamples[,1] %in% rep.names.short)
samples <- as.character(repsTOsamples.filtered$Sample...rep.name)
other.headers <- as.character(rep.names.short[1:4])
samples.vector <- noquote(c(other.headers, samples))
SRM.data <- SRMreport[-1,]
colnames(SRM.data) <- samples.vector
# Create separate reports for dilution curve data and sample data
SRM.dilution.data <- SRM.data[-1,c(grepl("Protein Name|Transition|Peptide Sequence|Fragment Ion|^D.-G$", colnames(SRM.data)))]  #dilution curve data
SRM.sample.data <- (SRM.data[,c(!grepl("^D.-G$", colnames(SRM.data)))]) #sample data
##Annotate sample names with Bay and Habitat
repsTOsamples.filtered.annotated <- merge(x=repsTOsamples.filtered, y=sample.key[,c("Bay", "Habitat", "Exclosure", "PRVial", "Sample.Shorthand")], by.x="Comment", by.y = "PRVial", all.x=T, all.y=F)
#as.data.frame(filter(sample.key[,c(3,5,6,8,9)], sample.key$PRVial %in% repsTOsamples.filtered$Comment)) #pull bay & habitat from sample key
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G053-remake"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("FB", "FB","E","E","FBE-2","FBE-2","FB-E","FB-E")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G071-A"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("PG","PG","E","E","PGE-2","PGE-2","PG-E","PG-E")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G071-B"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("PG","PG","E","E","PGE-2","PGE-2","PG-E","PG-E")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G104-remake"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("WB","WB","B","B","WBB-4","WBB-4","WB-B","WB-B")
repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Comment == "G114-remake"),c("Bay", "Habitat", "Exclosure", "Sample.Shorthand")] <- c("WB","WB","B","B","WBB-6","WBB-6","WB-B","WB-B")
repsTOsamples.filtered.annotated <- repsTOsamples.filtered.annotated[-1:-8,] #remove dilution curve sample info
# Subset sample names for site & treatment combos
CI.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "CI-E"),]
CI.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "CI-B"),]
PG.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "PG-E"),]
PG.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "PG-B"),]
WB.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "WB-E"),]
WB.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "WB-B"),]
FB.E <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "FB-E"),]
FB.B <- repsTOsamples.filtered.annotated[c(repsTOsamples.filtered.annotated$Sample.Shorthand == "FB-B"),]
# Isolate just sample names for each site/treatment combo
CI.E.samples <- unique(CI.E$Comment)
CI.B.samples <- unique(CI.B$Comment)
PG.E.samples <- unique(PG.E$Comment)
PG.B.samples <- unique(PG.B$Comment)
WB.E.samples <- unique(WB.E$Comment)
WB.B.samples <- unique(WB.B$Comment)
FB.E.samples <- unique(FB.E$Comment)
FB.B.samples <- unique(FB.B$Comment)
# Isolate eelgrass and bare group sample names
Eelgrass.samples <- c(CI.E.samples, PG.E.samples, WB.E.samples, FB.E.samples)
Bare.samples <- c(CI.B.samples, PG.B.samples, WB.B.samples, FB.B.samples)
### Convert Area data to numeric format
SRM.data.numeric[,5:120] <- as.numeric(as.character(unlist(SRM.data.numeric[,5:120]))) # NOTE: this is a handy method of converting tricky data to numeric
View(SRMreport)
# Join outlier-scrubbed master environmental dataset with metadata
data.melted.plus.pepsum <- read.csv("results/SRM/SRM-data-peptide-summed.csv", header=T)
data.melted.plus.pepsum
# Join outlier-scrubbed master environmental dataset with metadata
data.melted.plus.pepsum <- read.csv("results/SRM/SRM-data-peptide-summed.csv", header=T)[-1]
data.melted.plus.pepsum
metadata <- aggregate(Region ~ Bay + Habitat +Sample.Shorthand, data.melted.plus.pepsum, FUN=unique)
metadata
Env.Data.Master.noOuts.geo <- merge(x=Env.Data.Master.noOuts.geo, y=metadata, by.x = "variable", by.y = "Sample.Shorthand", all.x=T, all.y=T)
# Pull summary statistics for each environmental variable by location
EnvSum <- set_colnames(aggregate(value ~ variable*metric + Bay + Habitat + Region, Env.Data.Master.noOuts.geo, mean), c("variable", "metric", "Bay", "Habitat", "Region", "Mean"))
EnvSum$Median <- aggregate(value ~ variable*metric + Bay + Habitat + Region, Env.Data.Master.noOuts.geo, median)$value
EnvSum$sd <- aggregate(value ~ variable*metric + Bay + Habitat + Region, Env.Data.Master.noOuts.geo, sd)$value
EnvSum$Var <- aggregate(value ~ variable*metric + Bay + Habitat + Region, Env.Data.Master.noOuts.geo, var)$value
EnvSum$Min <- aggregate(value ~ variable*metric + Bay + Habitat + Region, Env.Data.Master.noOuts.geo, min)$value
EnvSum$Max <- aggregate(value ~ variable*metric + Bay + Habitat + Region, Env.Data.Master.noOuts.geo, max)$value
write.csv(file="results/Environmental/Environmental-summary-stats.csv", EnvSum, col.names = T, row.names=F )
EnvSum
# Grand mean, sd, variance values
aggregate(value ~ metric, Env.Data.Master.noOuts.geo, max)
aggregate(value ~ metric, Env.Data.Master.noOuts.geo, min)
aggregate(value ~ metric + Habitat , Env.Data.Master.noOuts.geo, mean)
aggregate(value ~ metric + Habitat , Env.Data.Master.noOuts.geo, sd)
aggregate(value ~ metric, Env.Data.Master.noOuts.geo, var)
# Correlation plots between summary stats within enviromental parameters
pairs(EnvSum[6:11]) # Independent parameters to use: Mean, Var
# Generate time-series of daily means, daily variance pH
# use dplyr and mutate to add a day column to your data
Env.Data.Master.noOuts.geo_daily <- Env.Data.Master.noOuts.geo %>%
mutate(Day = as.Date(DateTime, format = "%Y-%m-%d"))
# Calculate daily mean environmental parameters, excluding tidal heigh
Env.Data.Master.noOuts.geo_daily <- as.data.frame(subset(Env.Data.Master.noOuts.geo, !((metric=="Tide")))  %>%
mutate(Day = as.Date(DateTime, format = "%Y-%m-%d")) %>%
group_by(Day, variable, metric, Bay, Habitat, Region) %>% # group by the day column
summarise(daily.mean=mean(value), daily.sd=sd(value), daily.var=var(value), daily.min=min(value), daily.max=max(value)) %>%
na.omit())
# Calculate daily ranges for environmental parameters
Env.Data.Master.noOuts.geo_daily$range <- Env.Data.Master.noOuts.geo_daily$daily.max - Env.Data.Master.noOuts.geo_daily$daily.min
# View daily mean range by location
View(aggregate(range ~ metric + variable , Env.Data.Master.noOuts.geo_daily, mean))
# Calculate mean daily pH range across all locations
mean(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric == "pH"),]$range)
# Calculate SD of daily pH range across all locations
sd(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric == "pH"),]$range)
# Assess normality of daily means - pretty good
par(mfrow = c(2, 2))
for (i in 1:length(Env.parameters)) {
qqnorm(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.mean"], main = Env.parameters[[i]],
xlab = "Theoretical Quantiles", ylab = "Daily Mean Parameter Value", plot.it = TRUE)
qqline(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.mean"])}
for (i in 1:length(Env.parameters)) {
hist(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.mean"], main = Env.parameters[[i]], xlab = "Frequency")}
# Are daily means different between Bay, Habitats within Bay?
.05/16 # P-value needs to be below 0.003125
summary(pH.mean.lm <- lm(daily.mean ~ Bay*Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "pH"),]))
anova(pH.mean.lm)
anova(pH.mean.lm)[[5]]*16 #bonferroni corrected p-values for Bay, Habitat, and Bay*Habitat
anova(lm(daily.mean ~ Region, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "pH"),]))[[5]]*16  # Regional differences, corrected
summary(DO.mean.lm <- lm(daily.mean ~ Bay*Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "DO"),]))  #yes
anova(DO.mean.lm)
anova(DO.mean.lm)[[5]]*16
anova(lm(daily.mean ~ Region, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "DO"),]))[[5]]*16
summary(Temp.mean.lm <- lm(daily.mean ~ Bay* Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "Temperature"),])) #not between habitats
anova(Temp.mean.lm)
anova(Temp.mean.lm)[[5]]*16
anova(lm(daily.mean ~ Region, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "Temperature"),]))[[5]]*16
summary(Salin.mean.lm <- lm(daily.mean ~ Bay, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "Salinity"),]))  #yes
anova(Salin.mean.lm)
anova(Salin.mean.lm)[[5]]*16
anova(lm(daily.mean ~ Region, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "Salinity"),]))[[5]]*16  #Regional differences
# Assess normality of daily standard deviation - not normal.
par(mfrow = c(2, 2))
for (i in 1:length(Env.parameters)) {
qqnorm(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.sd"], main = Env.parameters[[i]],
xlab = "Theoretical Quantiles", ylab = "Daily Mean Parameter Value", plot.it = TRUE)
qqline(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.sd"])}
for (i in 1:length(Env.parameters)) {
hist(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.sd"], main = Env.parameters[[i]], xlab = "Frequency")}
#calculate lambda value to use to transform daily variances
par(mfrow = c(4, 3))
for (i in 1:length(Env.parameters)) {
print(Env.parameters[[i]])
transformTukey(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.sd"], plotit=TRUE, statistic = 1)
}
#Create new column in dataframe with lambda-transformed area data
Env.Data.Master.noOuts.geo_daily$sd.lambda <- c(rep("x", times=nrow(Env.Data.Master.noOuts.geo_daily)))
# Transform abundance data via its designated lambda value
sd.lambda <- c(0.175, 0.225, 0.875, -0.225) #pulled from console print-out
for (i in 1:length(Env.parameters)) {
Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"sd.lambda"] <-Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"daily.var"]^sd.lambda[i]
}
#convert lambda.t values to numeric
Env.Data.Master.noOuts.geo_daily$sd.lambda <- as.numeric(Env.Data.Master.noOuts.geo_daily$sd.lambda)
# Confirm normality of transformed daily std. dev
par(mfrow = c(2, 2))
for (i in 1:length(Env.parameters)) {
qqnorm(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"sd.lambda"], main = Env.parameters[[i]],
xlab = "Theoretical Quantiles", ylab = "Daily Mean Parameter Value", plot.it = TRUE)
qqline(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"sd.lambda"])}
for (i in 1:length(Env.parameters)) {
hist(Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% Env.parameters[i]),"sd.lambda"], main = Env.parameters[[i]], xlab = "Frequency")}
# Are daily sd different between Bay, Habitats within Bay?
summary(pH.sd.lm <- lm(sd.lambda ~ Bay*Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "pH"),])) #yes
anova(pH.sd.lm)
anova(pH.sd.lm)[[5]]*16
anova(lm(sd.lambda ~ Region, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "pH"),]))[[5]]*16
anova(pH.mean.lm)[[5]]*16 #bonferroni corrected p-values for Bay, Habitat, and Bay*Habitat
anova(pH.mean.lm)
anova(pH.mean.lm)[[5]]*16 #bonferroni corrected p-values for Bay, Habitat, and Bay*Habitat
# Are daily sd different between Bay, Habitats within Bay?
summary(pH.sd.lm <- lm(sd.lambda ~ Bay*Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "pH"),])) #yes
anova(pH.sd.lm)
anova(pH.sd.lm)[[5]]*16
summary(Temp.mean.lm <- lm(daily.mean ~ Bay* Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "Temperature"),])) #not between habitats
anova(Temp.mean.lm)
anova(Temp.mean.lm)[[5]]*16
summary(DO.mean.lm <- lm(daily.mean ~ Bay*Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "DO"),]))  #yes
anova(DO.mean.lm)
anova(DO.mean.lm)[[5]]*16
summary(DO.sd.lm <- lm(sd.lambda ~ Bay*Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "DO"),]))  #yes
anova(DO.sd.lm)
anova(DO.sd.lm)[[5]]*16
summary(Salin.mean.lm <- lm(daily.mean ~ Bay, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "Salinity"),]))  #yes
anova(Salin.mean.lm)
anova(Salin.mean.lm)[[5]]*16
anova(lm(Growth ~ Region, data=Growth)) # yes, growth differences between ad-hoc region
# Import growth data
Growth <- read.csv("data/GeoduckGrowth.csv", header=TRUE, stringsAsFactors = T, na.strings = "NA")
Growth$Growth <- Growth$FShell - Growth$AvgIShell
# Get growth summary stats
mean(Growth$AvgIShell) #Mean shell length prior to deployment
sd(Growth$AvgIShell) #SD shell length prior to deployment
mean(Growth$FShell) #Mean shell length at retrieval
sd(Growth$FShell) #SD shell length at retrieval
anova(lm(Growth ~ Bay*Habitat, data=Growth)) #no growth differences between habitats across all bays, so now look at all combination of bays
anova(lm(Growth ~ Bay, data=Growth)) # yes, growth differences between bays.
anova(lm(Growth ~ Region, data=Growth)) # yes, growth differences between ad-hoc region
anova(lm(Growth ~ Bay*Habitat, data=Growth)) #no growth differences between habitats across all bays, so now look at all combination of bays
# Import deployment latitude and longitude data
locationCords <- read.csv("data/Environmental/Deployment-Coordinates.csv", header = T, stringsAsFactors = T) #Import outplant coordinate information
locationCords <- locationCords[order(locationCords$Latitude),] #Reorder location coordinates by latittude (south to north)
locationCords.bay <- locationCords[c(2,4,6,7),] #pull out one set of coordinates for each bay
marker1 = c("sienna1", "goldenrod1", "steelblue2", "royalblue3") #marker colors for each bay, from south to north
symbols <- c(21, 22, 23, 24) #symbol shapes for each bay, south to north
data(nepacLLhigh) #Load set of polygons for the NE Pacific Ocean in high resolution from PBSmapping
library(maps) #Basic mapping functions and some data
library(mapdata)  #Some additional HiRes data
library(maptools) #Useful tools such as reading shapefiles
library(mapproj) #Various mapping projections
library(PBSmapping) #Powerful mapping functions developed by Pacific Biological Station
library(gridExtra)
library(cowplot)
data(nepacLLhigh) #Load set of polygons for the NE Pacific Ocean in high resolution from PBSmapping
#symbols <- c(21, 22, 23, 24) #symbol shapes for each bay, south to north
symbols <- c(24, 24, 24, 24) #use just one symbol shape,
data(nepacLLhigh) #Load set of polygons for the NE Pacific Ocean in high resolution from PBSmapping
# Create file to save map
# svg(filename = "results/Deployment-map.svg") # uncomment/comment depending on which file type you want
jpeg(filename = "results/Deployment-map.jpeg", width = 1000, height = 1000)
# Create base map of coastal WA state
plotMap(nepacLLhigh, xlim = c(-125, -121.9), ylim = c(46, 48.9), col = "gray92", bg = "gray85", xaxt = "n", yaxt = "n", xlab = "", ylab = "", ann = FALSE) #Create a map with high resolution NE Pacific Ocean data. Remove axes since those will be manually added
# Modify base map
axis(side = 1, at = c(-124.5, -124, -123.5, -123, -122.5), labels=c("124.5°W", "124°W", "123.5°W", "123°W", "122.5°W"), tick = TRUE, col.axis = "grey20") #Add longitude axis
axis(side = 2, at = c(46.5, 47, 47.5, 48, 48.5), labels=c("46.5ºN", "47°N", "47.5°N", "48°N", "48.5°N"), tick = TRUE, col.axis = "grey20") #Add latitude axis
#Add points to map
for (i in 1:length(symbols)) {
points(x = locationCords.bay$Longitude[i], y = locationCords.bay$Latitude[i], pch= symbols[i], add = TRUE, col = marker1[i], bg=marker1[i], lwd=2, cex=3.5)
}
# Add legend
legend("topleft", inset=0.05, legend=rev(locationCords.bay$Site), col=rev(marker1), cex=1.5, pt.cex = 3, pt.bg=rev(marker1), bg="gray92", pch=rev(symbols), box.lty=1, box.lwd=1, box.col="black")
dev.off() #Turn off plotting device
#symbols <- c(21, 22, 23, 24) #symbol shapes for each bay, south to north
symbols <- c(21, 21, 21, 21) #use just one symbol shape,
data(nepacLLhigh) #Load set of polygons for the NE Pacific Ocean in high resolution from PBSmapping
# Create file to save map
# svg(filename = "results/Deployment-map.svg") # uncomment/comment depending on which file type you want
jpeg(filename = "results/Deployment-map.jpeg", width = 1000, height = 1000)
# Create base map of coastal WA state
plotMap(nepacLLhigh, xlim = c(-125, -121.9), ylim = c(46, 48.9), col = "gray92", bg = "gray85", xaxt = "n", yaxt = "n", xlab = "", ylab = "", ann = FALSE) #Create a map with high resolution NE Pacific Ocean data. Remove axes since those will be manually added
# Modify base map
axis(side = 1, at = c(-124.5, -124, -123.5, -123, -122.5), labels=c("124.5°W", "124°W", "123.5°W", "123°W", "122.5°W"), tick = TRUE, col.axis = "grey20") #Add longitude axis
axis(side = 2, at = c(46.5, 47, 47.5, 48, 48.5), labels=c("46.5ºN", "47°N", "47.5°N", "48°N", "48.5°N"), tick = TRUE, col.axis = "grey20") #Add latitude axis
#Add points to map
for (i in 1:length(symbols)) {
points(x = locationCords.bay$Longitude[i], y = locationCords.bay$Latitude[i], pch= symbols[i], add = TRUE, col = marker1[i], bg=marker1[i], lwd=2, cex=3.5)
}
# Add legend
legend("topleft", inset=0.05, legend=rev(locationCords.bay$Site), col=rev(marker1), cex=1.5, pt.cex = 3, pt.bg=rev(marker1), bg="gray92", pch=rev(symbols), box.lty=1, box.lwd=1, box.col="black")
dev.off() #Turn off plotting device
# Create file to save map
# svg(filename = "results/Deployment-map.svg") # uncomment/comment depending on which file type you want
jpeg(filename = "results/Deployment-map.jpeg", width = 600, height = 600)
# Create base map of coastal WA state
plotMap(nepacLLhigh, xlim = c(-125, -121.9), ylim = c(46, 48.9), col = "gray92", bg = "gray85", xaxt = "n", yaxt = "n", xlab = "", ylab = "", ann = FALSE) #Create a map with high resolution NE Pacific Ocean data. Remove axes since those will be manually added
# Modify base map
axis(side = 1, at = c(-124.5, -124, -123.5, -123, -122.5), labels=c("124.5°W", "124°W", "123.5°W", "123°W", "122.5°W"), tick = TRUE, col.axis = "grey20") #Add longitude axis
axis(side = 2, at = c(46.5, 47, 47.5, 48, 48.5), labels=c("46.5ºN", "47°N", "47.5°N", "48°N", "48.5°N"), tick = TRUE, col.axis = "grey20") #Add latitude axis
#Add points to map
for (i in 1:length(symbols)) {
points(x = locationCords.bay$Longitude[i], y = locationCords.bay$Latitude[i], pch= symbols[i], add = TRUE, col = marker1[i], bg=marker1[i], lwd=2, cex=3.5)
}
# Add legend
legend("topleft", inset=0.05, legend=rev(locationCords.bay$Site), col=rev(marker1), cex=1.5, pt.cex = 3, pt.bg=rev(marker1), bg="gray92", pch=rev(symbols), box.lty=1, box.lwd=1, box.col="black")
dev.off() #Turn off plotting device
#----
group.colors2 <- c(`WB-U` = "sienna1", `WB-E` = "sienna3", `CI-U` = "goldenrod1", `CI-E` = "goldenrod3", `PG-U` ="steelblue2", `PG-E` ="steelblue3", `FB-U` = "royalblue3", `FB-E` = "royalblue4")
# Boxplot fill colors
group.colors3 <- c(`WB-U` = "white", `WB-E` = "sienna1", `CI-U` = "white", `CI-E` = "goldenrod1", `PG-U` ="white", `PG-E` ="steelblue2", `FB-U` = "white", `FB-E` = "royalblue3")
# Reorder factors geographically, north to south (FB -> PGB -> CI -> WB)
Growth$Both<-factor(Growth$Both, levels=c("FB-U", "FB-E", "PG-U", "PG-E", "CI-U", "CI-E", "WB-U", "WB-E"))
Growth$Bay<-factor(Growth$Bay, levels=c("FB", "PG", "CI", "WB"))
ggplot(Growth, aes(x=factor(Both), y=as.numeric(Growth), color=Both, fill=Both)) + geom_boxplot() + xlab("Location") + ylab("Growth (mm)") + scale_color_manual(values=group.colors2, labels=c("Willapa Bay", "Case Inlet", "Port Gamble Bay", "Fidalgo Bay")) + scale_fill_manual(values=group.colors3) + theme_light() + theme(plot.title = element_text(size=26, face="bold"), axis.text.y=element_text(size=28, angle=45, face="bold"), axis.text.x=element_text(size=24, angle=45, hjust=0.95, vjust=0.9), axis.title=element_text(size=28,face="bold"), legend.position = "none", panel.background = element_blank()) + ggtitle("Growth (mm) relative to \ninitial group length") + guides(fill = guide_legend(reverse = TRUE)) + theme(plot.margin=unit(c(.2,.2,.2,.2),"cm"), panel.border = element_rect(colour = "black", fill=NA, size=1)) + ylim(-3,8.25) +
annotate('segment', x = 4.75, xend = 8.25, y = 5, yend=5, colour="black") +
annotate('segment', x = 0.75, xend = 4.25, y = 6.5, yend=6.5, colour="black") +
annotate('segment', x = 2.5, xend = 6.5, y = 7.5, yend=7.5, colour="black") +
annotate('segment', x=2.5, xend=2.5, y=6.75, yend=7.5, colour="black") +
annotate('segment', x=6.5, xend=6.5, y=5.25, yend=7.5, colour="black") +
annotate("text", x=4.5, y=8, label =" p = 4.9e-11", size=7)
jpeg("results/Growth-plot.jpeg", width=700, height=700)
ggplot(Growth, aes(x=factor(Both), y=as.numeric(Growth), color=Both, fill=Both)) + geom_boxplot() + xlab("Location") + ylab("Growth (mm)") + scale_color_manual(values=group.colors2, labels=c("Willapa Bay", "Case Inlet", "Port Gamble Bay", "Fidalgo Bay")) + scale_fill_manual(values=group.colors3) + theme_light() + theme(plot.title = element_text(size=26, face="bold"), axis.text.y=element_text(size=28, angle=45, face="bold"), axis.text.x=element_text(size=24, angle=45, hjust=0.95, vjust=0.9), axis.title=element_text(size=28,face="bold"), legend.position = "none", panel.background = element_blank()) + ggtitle("Growth (mm) relative to \ninitial group length") + guides(fill = guide_legend(reverse = TRUE)) + theme(plot.margin=unit(c(.2,.2,.2,.2),"cm"), panel.border = element_rect(colour = "black", fill=NA, size=1)) + ylim(-3,8.25) +
annotate('segment', x = 4.75, xend = 8.25, y = 5, yend=5, colour="black") +
annotate('segment', x = 0.75, xend = 4.25, y = 6.5, yend=6.5, colour="black") +
annotate('segment', x = 2.5, xend = 6.5, y = 7.5, yend=7.5, colour="black") +
annotate('segment', x=2.5, xend=2.5, y=6.75, yend=7.5, colour="black") +
annotate('segment', x=6.5, xend=6.5, y=5.25, yend=7.5, colour="black") +
annotate("text", x=4.5, y=8, label =" p = 4.9e-11", size=7)
dev.off()
# generate ggplot boxplot for each protein, with base formatting
for (i in 1:length(Protein.names)) {
protein.plots[[i]] <-  ggplot(subset(data.melted.plus.promean, Protein==Protein.names[[i]]), aes(x=factor(Sample.Shorthand), y=value, color=Sample.Shorthand, fill=Sample.Shorthand)) + geom_boxplot() + scale_color_manual(values=group.colors2) + scale_fill_manual(values=group.colors3) + theme_light() + theme(plot.title = element_text(size=14, face="bold", margin=margin(0,0,2,0)), axis.title.y=element_blank(), axis.text.y=element_text(size=14, face="bold", angle=25), axis.text.x=element_text(size=14, angle=45, hjust=0.95, vjust=0.9, face="bold"), axis.title=element_text(size=14,face="bold"), legend.position = "none", panel.background = element_blank()) + ggtitle(Protein.names[[i]]) + guides(fill = guide_legend(reverse = TRUE)) + theme(plot.margin=unit(c(.1,.1,.1,.1),"cm"), panel.border = element_rect(colour = "black", fill=NA, size=1)) +   theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
}
data.melted.plus.promean
data.melted.plus
data.melted.plus.promean
# Read in, if needed
data.melted.plus.promean <- read.csv("results/SRM/SRM-data-protein-meanpeptide.csv")
data.melted.plus.promean
# Read in, if needed
data.melted.plus.promean <- read.csv("results/SRM/SRM-data-protein-meanpeptide.csv", header = T, row.names = F)
# Read in, if needed
data.melted.plus.promean <- read.csv("results/SRM/SRM-data-protein-meanpeptide.csv", header = T, row.names = 1)
data.melted.plus.promean
# Swap out "U" (unvegetated) for "B" (bare) in the location code
data.melted.plus.promean$Sample.Shorthand <- sub("-B", "-U", data.melted.plus.promean$Sample.Shorthand)
# Reorder factors geographically, north to south (FB -> PGB -> CI -> WB)
data.melted.plus.promean$Sample.Shorthand <- as.factor(data.melted.plus.promean$Sample.Shorthand)
data.melted.plus.promean$Sample.Shorthand<-factor(data.melted.plus.promean$Sample.Shorthand, levels=c("FB-U", "FB-E", "PG-U", "PG-E",  "CI-U", "CI-E", "WB-U", "WB-E"))
data.melted.plus.promean$Bay<-factor(data.melted.plus.promean$Bay, levels=c("FB", "PG", "CI", "WB"))
# create empty protein plot list
protein.plots <- vector("list", length(Protein.names))
names(protein.plots) <- Protein.names
unique(data.melted.plus.promean$Protein)
# create empty protein plot list
Protein.names <- unique(data.melted.plus.promean$Protein)
protein.plots <- vector("list", length(Protein.names))
names(protein.plots) <- Protein.names
# generate ggplot boxplot for each protein, with base formatting
for (i in 1:length(Protein.names)) {
protein.plots[[i]] <-  ggplot(subset(data.melted.plus.promean, Protein==Protein.names[[i]]), aes(x=factor(Sample.Shorthand), y=value, color=Sample.Shorthand, fill=Sample.Shorthand)) + geom_boxplot() + scale_color_manual(values=group.colors2) + scale_fill_manual(values=group.colors3) + theme_light() + theme(plot.title = element_text(size=14, face="bold", margin=margin(0,0,2,0)), axis.title.y=element_blank(), axis.text.y=element_text(size=14, face="bold", angle=25), axis.text.x=element_text(size=14, angle=45, hjust=0.95, vjust=0.9, face="bold"), axis.title=element_text(size=14,face="bold"), legend.position = "none", panel.background = element_blank()) + ggtitle(Protein.names[[i]]) + guides(fill = guide_legend(reverse = TRUE)) + theme(plot.margin=unit(c(.1,.1,.1,.1),"cm"), panel.border = element_rect(colour = "black", fill=NA, size=1)) +   theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
}
# customize each boxplot with title, and y axis, and last 2 plots with x-axis text and title
protein.plots[[1]] <- protein.plots[[1]] + ggtitle("arachidonate 5-lipoxygenase") + scale_y_continuous(labels=scales::scientific, breaks=c(1e6, 2e6, 3e6))
protein.plots[[2]] <- protein.plots[[2]] + ggtitle("catalase") + scale_y_continuous(labels=scales::scientific)
protein.plots[[3]] <- protein.plots[[3]] + ggtitle("cytochrome P450") + scale_y_continuous(labels=scales::scientific, breaks=c(2e5, 4e5, 6e5))
protein.plots[[4]] <- protein.plots[[4]] + ggtitle("glycogen phosphorylase") + scale_y_continuous(labels=scales::scientific, breaks=c(3e5, 5.5e5, 8e5))
# protein.plots[[5]] <- do not include HSP70 (omitted in screening)
protein.plots[[6]] <- protein.plots[[6]] + ggtitle("**heat shock protein 90-alpha") + scale_y_continuous(labels=scales::scientific, breaks=c(2e6, 4e6, 6e6))
protein.plots[[7]] <- protein.plots[[7]] + ggtitle("protein disulfide-isomerase") + scale_y_continuous(labels=scales::scientific, breaks=c(1.5e6, 2.5e6, 3.5e6))
# protein.plots[[8]]  <- do not include Peroxiredoxin-1 (omitted in screening)
protein.plots[[9]] <- protein.plots[[9]] + ggtitle("*puromycin-sensitive aminopeptidase") + scale_y_continuous(labels=scales::scientific, breaks=c(2e5, 6e5, 1e6))
# protein.plots[[10]] <- do not include Ras-related protein (omitted in screening)
protein.plots[[11]] <- protein.plots[[11]] + ggtitle("Na/K-transporting ATPase") + scale_y_continuous(labels=scales::scientific, breaks=c(1.3e5, 2.5e5, 3.7e5))
protein.plots[[12]] <- protein.plots[[12]] + xlab("Location") + theme(axis.text.x=element_text(size=14, angle=45, hjust=0.95, vjust=0.9, face="bold"), axis.title.x=element_text(size=14,face="bold")) + ggtitle("superoxide dismutase") + scale_y_continuous(labels=scales::scientific, breaks=c(2e5, 4e5, 6e5))
protein.plots[[13]] <- protein.plots[[13]] + xlab("Location") + theme(axis.text.x=element_text(size=14, angle=45, hjust=0.95, vjust=0.9, face="bold"), axis.title.x=element_text(size=14,face="bold")) + ggtitle("**trifunctional enzyme β-subunit") + scale_y_continuous(labels=scales::scientific, breaks=c(6e4, 1.4e5, 2.2e5))
jpeg(filename = "results/SRM/Protein-plots-paper.jpeg", width = 850, height = 1250)
plot_grid(protein.plots[[1]],
protein.plots[[2]],
protein.plots[[3]],
protein.plots[[4]],
protein.plots[[6]],
protein.plots[[7]],
protein.plots[[9]],
protein.plots[[11]],
protein.plots[[12]],
protein.plots[[13]],
align = "v",
nrow=5,
rel_heights = c(rep(.5, times=4), 0.7)) #adjust row heights so plots in last row aren't smaller (they have x-axis text)
dev.off()
# Are daily sd different between Bay, Habitats within Bay?
summary(pH.sd.lm <- lm(sd.lambda ~ Bay*Habitat, data=Env.Data.Master.noOuts.geo_daily[which(Env.Data.Master.noOuts.geo_daily$metric %in% "pH"),])) #yes
anova(pH.sd.lm)
